{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# First Practical Laboratory: Deep Learning Architecture Experimentation\n",
        "\n",
        "**Machine Learning Technologies (MUCEIM)**\n",
        "\n",
        "**Student Name:** [Your Full Name Here]\n",
        "\n",
        "**Date:** [Submission Date]\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. **Make a copy** of this notebook to your own Google Drive (`File > Save a copy in Drive`) and be sure you select a Runtime with GPU\n",
        "2. **Fill in all empty code cells** as instructed\n",
        "3. **Document your analysis** in the markdown cells provided\n",
        "4. **Ensure the entire notebook runs** from top to bottom without errors (`Runtime > Restart and run all`)\n",
        "5. **Share the final notebook** with \"Anyone with the link can view\" and include the link in your PDF report\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section1"
      },
      "source": [
        "## 1. Import Libraries\n",
        "\n",
        "Import all necessary libraries for your experiments. Common libraries include TensorFlow/Keras, NumPy, Matplotlib, and Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Check TensorFlow version\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Check if GPU is available\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# --- Helper Functions for Plotting ---\n",
        "def plot_acc(history, title=\"Model Accuracy\"):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "def plot_loss(history, title=\"Model Loss\"):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "def plot_compare_losses(history1, history2, name1=\"Model 1\",\n",
        "                        name2=\"Model 2\", title=\"Graph title\"):\n",
        "    plt.plot(history1.history['loss'], color=\"green\")\n",
        "    plt.plot(history1.history['val_loss'], 'r--', color=\"green\")\n",
        "    plt.plot(history2.history['loss'], color=\"blue\")\n",
        "    plt.plot(history2.history['val_loss'], 'r--', color=\"blue\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train ' + name1, 'Val ' + name1,\n",
        "                'Train ' + name2, 'Val ' + name2],\n",
        "               loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "def plot_compare_accs(history1, history2, name1=\"Model 1\",\n",
        "                      name2=\"Model 2\", title=\"Graph title\"):\n",
        "    plt.plot(history1.history['accuracy'], color=\"green\")\n",
        "    plt.plot(history1.history['val_accuracy'], 'r--', color=\"green\")\n",
        "    plt.plot(history2.history['accuracy'], color=\"blue\")\n",
        "    plt.plot(history2.history['val_accuracy'], 'r--', color=\"blue\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train ' + name1, 'Val ' + name1,\n",
        "                'Train ' + name2, 'Val ' + name2],\n",
        "               loc='lower right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section2"
      },
      "source": [
        "## 2. Dataset Selection and Loading\n",
        "\n",
        "Choose your dataset from the options provided in the assignment document:\n",
        "- MNIST\n",
        "- Fashion MNIST\n",
        "- CIFAR-10\n",
        "- Custom dataset (with justification)\n",
        "\n",
        "Load and inspect the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "# Load Fashion MNIST dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inspect_data"
      },
      "outputs": [],
      "source": [
        "# Inspect the dataset\n",
        "print(f\"Training data shape: {x_train.shape}\")\n",
        "print(f\"Test data shape: {x_test.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(y_train))}\")\n",
        "\n",
        "# Visualize sample images\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataset_justification"
      },
      "source": [
        "### Dataset Choice Justification\n",
        "\n",
        "**Dataset Selected:** Fashion MNIST\n",
        "\n",
        "**Justification:** I chose Fashion MNIST because it is a drop-in replacement for MNIST but offers a slightly more challenging classification task. While MNIST digits are very simple and can be classified with high accuracy by even simple linear models, Fashion MNIST images have more complex structures and textures, making it a better benchmark for observing the effects of architectural changes, regularization, and optimization strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section3"
      },
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "Apply necessary preprocessing steps:\n",
        "- Normalization (e.g., scaling pixel values to [0,1])\n",
        "- One-hot encoding for labels (if needed)\n",
        "- Train/validation split\n",
        "- Any dataset-specific preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocess"
      },
      "outputs": [],
      "source": [
        "# Preprocessing code\n",
        "\n",
        "# 1. Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# 2. Reshape data (Flattening 28x28 images to 784 vectors for MLP)\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "# 3. Cast to float32\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# 4. One-hot encoding of labels\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Preprocessing complete.\")\n",
        "print(f\"New x_train shape: {x_train.shape}\")\n",
        "print(f\"New y_train shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section4"
      },
      "source": [
        "## 4. Baseline Model\n",
        "\n",
        "Define, compile, and train a simple baseline model. This will serve as your point of comparison for all subsequent experiments.\n",
        "\n",
        "**Baseline Architecture Description:**\n",
        "The baseline model is a Multi-Layer Perceptron (MLP) with 3 hidden layers using **Sigmoid** activation functions. \n",
        "- Input Layer: 784 neurons (flattened image)\n",
        "- Hidden Layer 1: 128 neurons, Sigmoid\n",
        "- Hidden Layer 2: 128 neurons, Sigmoid\n",
        "- Hidden Layer 3: 64 neurons, Sigmoid\n",
        "- Output Layer: 10 neurons, Softmax\n",
        "- Optimizer: SGD\n",
        "- Loss: Categorical Crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_model"
      },
      "outputs": [],
      "source": [
        "# Define baseline model (Sigmoid)\n",
        "def create_baseline_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='sigmoid', input_shape=(784,)),\n",
        "        Dense(128, activation='sigmoid'),\n",
        "        Dense(64, activation='sigmoid'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_baseline = create_baseline_model()\n",
        "model_baseline.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_compile"
      },
      "outputs": [],
      "source": [
        "# Compile baseline model\n",
        "model_baseline.compile(loss='categorical_crossentropy',\n",
        "                       optimizer='sgd',\n",
        "                       metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_train"
      },
      "outputs": [],
      "source": [
        "# Train baseline model\n",
        "batch_size = 32\n",
        "epochs = 100  # Set high, rely on early stopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "\n",
        "history_baseline = model_baseline.fit(x_train, y_train,\n",
        "                                      batch_size=batch_size,\n",
        "                                      epochs=epochs,\n",
        "                                      verbose=1,\n",
        "                                      validation_split=0.2,\n",
        "                                      callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baseline_analysis_header"
      },
      "source": [
        "### Analysis of Baseline Model\n",
        "\n",
        "Plot the training history and evaluate the model. Analyze its performance characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_plot"
      },
      "outputs": [],
      "source": [
        "# Plot training history (loss and accuracy)\n",
        "plot_loss(history_baseline, title='Baseline (Sigmoid) Model Loss')\n",
        "plot_acc(history_baseline, title='Baseline (Sigmoid) Model Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_evaluate"
      },
      "outputs": [],
      "source": [
        "# Evaluate baseline model on test set\n",
        "test_loss, test_acc = model_baseline.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Baseline Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Baseline Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baseline_analysis"
      },
      "source": [
        "**Baseline Model Analysis:**\n",
        "\n",
        "The baseline model uses Sigmoid activation. Sigmoid functions can suffer from the vanishing gradient problem in deeper networks, which might lead to slower convergence or lower final accuracy compared to modern activations like ReLU. We will observe the training dynamics to see if this limitation is visible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section5"
      },
      "source": [
        "## 5. Systematic Experimentation\n",
        "\n",
        "Conduct at least **THREE** systematic experiments. For each experiment:\n",
        "1. State your hypothesis clearly\n",
        "2. Implement the architectural variation\n",
        "3. Train and evaluate the model\n",
        "4. Plot and analyze the results\n",
        "5. Compare with the baseline\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp1_header"
      },
      "source": [
        "### Experiment 1: Effect of Network Depth\n",
        "\n",
        "**Hypothesis:** Increasing the network depth by adding more hidden layers will allow the model to learn more complex hierarchical features. However, with Sigmoid activation, this might exacerbate the vanishing gradient problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp1_model"
      },
      "outputs": [],
      "source": [
        "# Define Experiment 1 model (Deeper Network with Sigmoid)\n",
        "def create_deep_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='sigmoid', input_shape=(784,)),\n",
        "        Dense(128, activation='sigmoid'),\n",
        "        Dense(128, activation='sigmoid'), # Added layer\n",
        "        Dense(128, activation='sigmoid'), # Added layer\n",
        "        Dense(64, activation='sigmoid'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_depth = create_deep_model()\n",
        "model_depth.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp1_train"
      },
      "outputs": [],
      "source": [
        "# Compile and train Experiment 1 model\n",
        "model_depth.compile(loss='categorical_crossentropy',\n",
        "                    optimizer='sgd',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "history_depth = model_depth.fit(x_train, y_train,\n",
        "                                batch_size=batch_size,\n",
        "                                epochs=epochs,\n",
        "                                verbose=1,\n",
        "                                validation_split=0.2,\n",
        "                                callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp1_analysis_header"
      },
      "source": [
        "#### Analysis of Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp1_plot"
      },
      "outputs": [],
      "source": [
        "# Plot results and compare with baseline\n",
        "plot_loss(history_depth, title='Deep Model (Sigmoid) Loss')\n",
        "plot_acc(history_depth, title='Deep Model (Sigmoid) Accuracy')\n",
        "\n",
        "plot_compare_accs(history_baseline, history_depth, name1=\"Baseline (Sigmoid)\", name2=\"Deep Model (Sigmoid)\", title=\"Baseline vs Deep Model Accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp1_analysis"
      },
      "source": [
        "**Experiment 1 Analysis:**\n",
        "\n",
        "We compare the validation accuracy of the deeper model against the baseline. If the deeper model struggles to train or performs worse, it confirms the difficulty of training deep networks with Sigmoid activations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp2_header"
      },
      "source": [
        "---\n",
        "\n",
        "### Experiment 2: Effect of Dropout Regularization\n",
        "\n",
        "**Hypothesis:** Adding Dropout layers will reduce overfitting. Even with Sigmoid, dropout should help generalization, although it might slow down convergence further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp2_model"
      },
      "outputs": [],
      "source": [
        "# Define Experiment 2 model (With Dropout and Sigmoid)\n",
        "def create_dropout_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='sigmoid', input_shape=(784,)),\n",
        "        Dropout(0.3), # Dropout layer\n",
        "        Dense(128, activation='sigmoid'),\n",
        "        Dropout(0.3), # Dropout layer\n",
        "        Dense(64, activation='sigmoid'),\n",
        "        Dropout(0.3), # Dropout layer\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_dropout = create_dropout_model()\n",
        "model_dropout.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp2_train"
      },
      "outputs": [],
      "source": [
        "# Compile and train Experiment 2 model\n",
        "model_dropout.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='sgd',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "history_dropout = model_dropout.fit(x_train, y_train,\n",
        "                                    batch_size=batch_size,\n",
        "                                    epochs=epochs,\n",
        "                                    verbose=1,\n",
        "                                    validation_split=0.2,\n",
        "                                    callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp2_analysis_header"
      },
      "source": [
        "#### Analysis of Experiment 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp2_plot"
      },
      "outputs": [],
      "source": [
        "# Plot results and compare with baseline\n",
        "plot_loss(history_dropout, title='Dropout Model (Sigmoid) Loss')\n",
        "plot_acc(history_dropout, title='Dropout Model (Sigmoid) Accuracy')\n",
        "\n",
        "plot_compare_accs(history_baseline, history_dropout, name1=\"Baseline\", name2=\"Dropout\", title=\"Baseline vs Dropout Accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp2_analysis"
      },
      "source": [
        "**Experiment 2 Analysis:**\n",
        "\n",
        "We look for a smaller gap between the training and validation curves compared to the baseline, indicating reduced overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp3_header"
      },
      "source": [
        "---\n",
        "\n",
        "### Experiment 3: Comparison of Activation Functions (Sigmoid vs ReLU)\n",
        "\n",
        "**Hypothesis:** Replacing the Sigmoid activation function with **ReLU** (Rectified Linear Unit) will significantly improve convergence speed and final accuracy. ReLU mitigates the vanishing gradient problem, allowing the network to learn faster and more effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp3_model"
      },
      "outputs": [],
      "source": [
        "# Define Experiment 3 model (ReLU Activation)\n",
        "def create_relu_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(784,)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_relu = create_relu_model()\n",
        "model_relu.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp3_train"
      },
      "outputs": [],
      "source": [
        "# Compile and train Experiment 3 model with ReLU\n",
        "model_relu.compile(loss='categorical_crossentropy',\n",
        "                   optimizer='sgd',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "history_relu = model_relu.fit(x_train, y_train,\n",
        "                              batch_size=batch_size,\n",
        "                              epochs=epochs,\n",
        "                              verbose=1,\n",
        "                              validation_split=0.2,\n",
        "                              callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp3_analysis_header"
      },
      "source": [
        "#### Analysis of Experiment 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp3_plot"
      },
      "outputs": [],
      "source": [
        "# Plot results and compare with baseline\n",
        "plot_loss(history_relu, title='ReLU Model Loss')\n",
        "plot_acc(history_relu, title='ReLU Model Accuracy')\n",
        "\n",
        "plot_compare_accs(history_baseline, history_relu, name1=\"Baseline (Sigmoid)\", name2=\"ReLU\", title=\"Sigmoid vs ReLU Accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp3_analysis"
      },
      "source": [
        "**Experiment 3 Analysis:**\n",
        "\n",
        "ReLU is expected to outperform Sigmoid. We compare the learning curves to see if ReLU converges faster (steeper initial slope) and reaches a higher final accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section6"
      },
      "source": [
        "---\n",
        "\n",
        "## 6. Comprehensive Comparison\n",
        "\n",
        "Create a summary comparison of all your experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison_table"
      },
      "outputs": [],
      "source": [
        "# Create a comparison table of all experiments\n",
        "results = {\n",
        "    \"Model\": [\"Baseline (Sigmoid)\", \"Deep Network (Sigmoid)\", \"Dropout (Sigmoid)\", \"ReLU Activation\"],\n",
        "    \"Final Val Accuracy\": [\n",
        "        max(history_baseline.history['val_accuracy']),\n",
        "        max(history_depth.history['val_accuracy']),\n",
        "        max(history_dropout.history['val_accuracy']),\n",
        "        max(history_relu.history['val_accuracy'])\n",
        "    ],\n",
        "    \"Final Val Loss\": [\n",
        "        min(history_baseline.history['val_loss']),\n",
        "        min(history_depth.history['val_loss']),\n",
        "        min(history_dropout.history['val_loss']),\n",
        "        min(history_relu.history['val_loss'])\n",
        "    ],\n",
        "    \"Epochs Trained\": [\n",
        "        len(history_baseline.history['loss']),\n",
        "        len(history_depth.history['loss']),\n",
        "        len(history_dropout.history['loss']),\n",
        "        len(history_relu.history['loss'])\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison_plot"
      },
      "outputs": [],
      "source": [
        "# Create comparative visualizations\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(history_baseline.history['val_accuracy'], label='Baseline (Sigmoid)', linestyle='--')\n",
        "plt.plot(history_depth.history['val_accuracy'], label='Deep Network (Sigmoid)')\n",
        "plt.plot(history_dropout.history['val_accuracy'], label='Dropout (Sigmoid)')\n",
        "plt.plot(history_relu.history['val_accuracy'], label='ReLU Activation')\n",
        "\n",
        "plt.title('Validation Accuracy Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section7"
      },
      "source": [
        "## 7. Final Conclusion\n",
        "\n",
        "Summarize your key findings from all experiments. What are the main takeaways about designing effective neural network architectures for your chosen problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "**Key Findings:**\n",
        "\n",
        "Based on the experiments conducted:\n",
        "1. **Baseline (Sigmoid):** The Sigmoid baseline likely showed slower convergence and potentially lower accuracy due to the vanishing gradient problem.\n",
        "2. **Depth & Dropout:** Increasing depth or adding dropout with Sigmoid might have had mixed results, as the fundamental limitation was the activation function.\n",
        "3. **Activation Function (ReLU):** Switching to ReLU (Experiment 3) likely provided the most significant performance boost, demonstrating why it is the standard choice for modern deep learning.\n",
        "\n",
        "**Recommendation:** For Fashion MNIST, using ReLU activation is critical. Once ReLU is adopted, further improvements can be sought through depth, regularization, and advanced optimizers (like Adam)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section8"
      },
      "source": [
        "## 8. AI Assistant Usage Documentation\n",
        "\n",
        "Document how you used AI assistants in this laboratory work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai_usage"
      },
      "source": [
        "**AI Assistants Used:** Google DeepMind AI Assistant\n",
        "\n",
        "**How I Used AI Assistants:**\n",
        "\n",
        "- I provided the AI with the assignment PDF and a reference notebook from the teacher.\n",
        "- The AI analyzed the requirements and the reference code.\n",
        "- The AI generated the complete code for the notebook, including data loading, preprocessing, the baseline model, and three systematic experiments.\n",
        "- **Modification:** I specifically requested the AI to change the baseline to use Sigmoid activation and to design Experiment 3 as a comparison between Sigmoid and ReLU, replacing the original optimizer experiment.\n",
        "- The AI also generated the plotting and comparison code.\n",
        "\n",
        "**Code Sections Influenced by AI:**\n",
        "\n",
        "- All code cells were generated by the AI based on the reference material and standard Keras practices.\n",
        "\n",
        "**My Understanding:**\n",
        "\n",
        "- I have reviewed the generated code and understand that it uses the Keras Sequential API to build models.\n",
        "- I understand the purpose of the three experiments: testing depth, regularization, and activation functions.\n",
        "- I can explain how the `plot_compare_accs` function works to visualize the differences between models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "footer"
      },
      "source": [
        "---\n",
        "\n",
        "## Submission Checklist\n",
        "\n",
        "Before submitting, ensure you have:\n",
        "\n",
        "- [ ] Filled in your name and date at the top of this notebook\n",
        "- [ ] Completed all required sections and code cells\n",
        "- [ ] Run the entire notebook from top to bottom without errors (`Runtime > Restart and run all`)\n",
        "- [ ] Documented your analysis in all markdown cells\n",
        "- [ ] Created clear and informative visualizations\n",
        "- [ ] Documented your AI assistant usage\n",
        "- [ ] Shared this notebook with \"Anyone with the link can view\"\n",
        "- [ ] Included the link to this notebook in your PDF report\n",
        "- [ ] Prepared your PDF report with all required sections\n",
        "\n",
        "**Good luck!**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}