{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# First Practical Laboratory: Deep Learning Architecture Experimentation\n",
        "\n",
        "**Machine Learning Technologies (MUCEIM)**\n",
        "\n",
        "**Student Name:** [Your Full Name Here]\n",
        "\n",
        "**Date:** [Submission Date]\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. **Make a copy** of this notebook to your own Google Drive (`File > Save a copy in Drive`) and be sure you select a Runtime with GPU\n",
        "2. **Fill in all empty code cells** as instructed\n",
        "3. **Document your analysis** in the markdown cells provided\n",
        "4. **Ensure the entire notebook runs** from top to bottom without errors (`Runtime > Restart and run all`)\n",
        "5. **Share the final notebook** with \"Anyone with the link can view\" and include the link in your PDF report\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section1"
      },
      "source": [
        "## 1. Import Libraries\n",
        "\n",
        "Import all necessary libraries for your experiments. Common libraries include TensorFlow/Keras, NumPy, Matplotlib, and Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Check TensorFlow version\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Check if GPU is available\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# --- Helper Functions for Plotting ---\n",
        "def plot_acc(history, title=\"Model Accuracy\"):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "def plot_loss(history, title=\"Model Loss\"):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "def plot_compare_losses(history1, history2, name1=\"Model 1\",\n",
        "                        name2=\"Model 2\", title=\"Graph title\"):\n",
        "    plt.plot(history1.history['loss'], color=\"green\")\n",
        "    plt.plot(history1.history['val_loss'], 'r--', color=\"green\")\n",
        "    plt.plot(history2.history['loss'], color=\"blue\")\n",
        "    plt.plot(history2.history['val_loss'], 'r--', color=\"blue\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train ' + name1, 'Val ' + name1,\n",
        "                'Train ' + name2, 'Val ' + name2],\n",
        "               loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "def plot_compare_accs(history1, history2, name1=\"Model 1\",\n",
        "                      name2=\"Model 2\", title=\"Graph title\"):\n",
        "    plt.plot(history1.history['accuracy'], color=\"green\")\n",
        "    plt.plot(history1.history['val_accuracy'], 'r--', color=\"green\")\n",
        "    plt.plot(history2.history['accuracy'], color=\"blue\")\n",
        "    plt.plot(history2.history['val_accuracy'], 'r--', color=\"blue\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train ' + name1, 'Val ' + name1,\n",
        "                'Train ' + name2, 'Val ' + name2],\n",
        "               loc='lower right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section2"
      },
      "source": [
        "## 2. Dataset Selection and Loading\n",
        "\n",
        "Choose your dataset from the options provided in the assignment document:\n",
        "- MNIST\n",
        "- Fashion MNIST\n",
        "- CIFAR-10\n",
        "- Custom dataset (with justification)\n",
        "\n",
        "Load and inspect the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "# Load Fashion MNIST dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inspect_data"
      },
      "outputs": [],
      "source": [
        "# Inspect the dataset\n",
        "print(f\"Training data shape: {x_train.shape}\")\n",
        "print(f\"Test data shape: {x_test.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(y_train))}\")\n",
        "\n",
        "# Visualize sample images\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataset_justification"
      },
      "source": [
        "### Dataset Choice Justification\n",
        "\n",
        "**Dataset Selected:** Fashion MNIST\n",
        "\n",
        "**Justification:** I chose Fashion MNIST because it is a drop-in replacement for MNIST but offers a slightly more challenging classification task. While MNIST digits are very simple and can be classified with high accuracy by even simple linear models, Fashion MNIST images have more complex structures and textures, making it a better benchmark for observing the effects of architectural changes, regularization, and optimization strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section3"
      },
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "Apply necessary preprocessing steps:\n",
        "- Normalization (e.g., scaling pixel values to [0,1])\n",
        "- One-hot encoding for labels (if needed)\n",
        "- Train/validation split\n",
        "- Any dataset-specific preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocess"
      },
      "outputs": [],
      "source": [
        "# Preprocessing code\n",
        "\n",
        "# 1. Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# 2. Reshape data (Flattening 28x28 images to 784 vectors for MLP)\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "# 3. Cast to float32\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# 4. One-hot encoding of labels\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Preprocessing complete.\")\n",
        "print(f\"New x_train shape: {x_train.shape}\")\n",
        "print(f\"New y_train shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section4"
      },
      "source": [
        "## 4. Baseline Model\n",
        "\n",
        "Define, compile, and train a simple baseline model. This will serve as your point of comparison for all subsequent experiments.\n",
        "\n",
        "**Baseline Architecture Description:**\n",
        "The baseline model is a Multi-Layer Perceptron (MLP) with 3 hidden layers using ReLU activation functions. \n",
        "- Input Layer: 784 neurons (flattened image)\n",
        "- Hidden Layer 1: 128 neurons, ReLU\n",
        "- Hidden Layer 2: 128 neurons, ReLU\n",
        "- Hidden Layer 3: 64 neurons, ReLU\n",
        "- Output Layer: 10 neurons, Softmax\n",
        "- Optimizer: SGD\n",
        "- Loss: Categorical Crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_model"
      },
      "outputs": [],
      "source": [
        "# Define baseline model\n",
        "def create_baseline_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(784,)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_baseline = create_baseline_model()\n",
        "model_baseline.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_compile"
      },
      "outputs": [],
      "source": [
        "# Compile baseline model\n",
        "model_baseline.compile(loss='categorical_crossentropy',\n",
        "                       optimizer='sgd',\n",
        "                       metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_train"
      },
      "outputs": [],
      "source": [
        "# Train baseline model\n",
        "batch_size = 32\n",
        "epochs = 100  # Set high, rely on early stopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "\n",
        "history_baseline = model_baseline.fit(x_train, y_train,\n",
        "                                      batch_size=batch_size,\n",
        "                                      epochs=epochs,\n",
        "                                      verbose=1,\n",
        "                                      validation_split=0.2,\n",
        "                                      callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baseline_analysis_header"
      },
      "source": [
        "### Analysis of Baseline Model\n",
        "\n",
        "Plot the training history and evaluate the model. Analyze its performance characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_plot"
      },
      "outputs": [],
      "source": [
        "# Plot training history (loss and accuracy)\n",
        "plot_loss(history_baseline, title='Baseline Model Loss')\n",
        "plot_acc(history_baseline, title='Baseline Model Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_evaluate"
      },
      "outputs": [],
      "source": [
        "# Evaluate baseline model on test set\n",
        "test_loss, test_acc = model_baseline.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Baseline Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Baseline Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baseline_analysis"
      },
      "source": [
        "**Baseline Model Analysis:**\n",
        "\n",
        "The baseline model uses ReLU activation which generally performs better than Sigmoid for deep networks as it helps mitigate the vanishing gradient problem. We observe the training and validation curves to check for overfitting. If the training accuracy continues to rise while validation accuracy plateaus or decreases, the model is overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section5"
      },
      "source": [
        "## 5. Systematic Experimentation\n",
        "\n",
        "Conduct at least **THREE** systematic experiments. For each experiment:\n",
        "1. State your hypothesis clearly\n",
        "2. Implement the architectural variation\n",
        "3. Train and evaluate the model\n",
        "4. Plot and analyze the results\n",
        "5. Compare with the baseline\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp1_header"
      },
      "source": [
        "### Experiment 1: Effect of Network Depth\n",
        "\n",
        "**Hypothesis:** Increasing the network depth by adding more hidden layers will allow the model to learn more complex hierarchical features, potentially improving accuracy. However, it may also make the model harder to train or more prone to overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp1_model"
      },
      "outputs": [],
      "source": [
        "# Define Experiment 1 model (Deeper Network)\n",
        "def create_deep_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(784,)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(128, activation='relu'), # Added layer\n",
        "        Dense(128, activation='relu'), # Added layer\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_depth = create_deep_model()\n",
        "model_depth.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp1_train"
      },
      "outputs": [],
      "source": [
        "# Compile and train Experiment 1 model\n",
        "model_depth.compile(loss='categorical_crossentropy',\n",
        "                    optimizer='sgd',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "history_depth = model_depth.fit(x_train, y_train,\n",
        "                                batch_size=batch_size,\n",
        "                                epochs=epochs,\n",
        "                                verbose=1,\n",
        "                                validation_split=0.2,\n",
        "                                callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp1_analysis_header"
      },
      "source": [
        "#### Analysis of Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp1_plot"
      },
      "outputs": [],
      "source": [
        "# Plot results and compare with baseline\n",
        "plot_loss(history_depth, title='Deep Model Loss')\n",
        "plot_acc(history_depth, title='Deep Model Accuracy')\n",
        "\n",
        "plot_compare_accs(history_baseline, history_depth, name1=\"Baseline\", name2=\"Deep Model\", title=\"Baseline vs Deep Model Accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp1_analysis"
      },
      "source": [
        "**Experiment 1 Analysis:**\n",
        "\n",
        "We compare the validation accuracy of the deeper model against the baseline. If the deeper model achieves higher accuracy, it suggests the extra capacity was beneficial. If it performs worse or overfits earlier, the added complexity might be unnecessary for this specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp2_header"
      },
      "source": [
        "---\n",
        "\n",
        "### Experiment 2: Effect of Dropout Regularization\n",
        "\n",
        "**Hypothesis:** Adding Dropout layers will reduce overfitting by preventing neurons from co-adapting too much. This should lead to a smaller gap between training and validation accuracy, potentially improving generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp2_model"
      },
      "outputs": [],
      "source": [
        "# Define Experiment 2 model (With Dropout)\n",
        "def create_dropout_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(784,)),\n",
        "        Dropout(0.3), # Dropout layer\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3), # Dropout layer\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3), # Dropout layer\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_dropout = create_dropout_model()\n",
        "model_dropout.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp2_train"
      },
      "outputs": [],
      "source": [
        "# Compile and train Experiment 2 model\n",
        "model_dropout.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='sgd',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "history_dropout = model_dropout.fit(x_train, y_train,\n",
        "                                    batch_size=batch_size,\n",
        "                                    epochs=epochs,\n",
        "                                    verbose=1,\n",
        "                                    validation_split=0.2,\n",
        "                                    callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp2_analysis_header"
      },
      "source": [
        "#### Analysis of Experiment 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp2_plot"
      },
      "outputs": [],
      "source": [
        "# Plot results and compare with baseline\n",
        "plot_loss(history_dropout, title='Dropout Model Loss')\n",
        "plot_acc(history_dropout, title='Dropout Model Accuracy')\n",
        "\n",
        "plot_compare_accs(history_baseline, history_dropout, name1=\"Baseline\", name2=\"Dropout\", title=\"Baseline vs Dropout Accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp2_analysis"
      },
      "source": [
        "**Experiment 2 Analysis:**\n",
        "\n",
        "Dropout typically slows down convergence but results in a more robust model. We look for a smaller gap between the training and validation curves compared to the baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp3_header"
      },
      "source": [
        "---\n",
        "\n",
        "### Experiment 3: Comparison of Optimizers (Adam vs SGD)\n",
        "\n",
        "**Hypothesis:** The Adam optimizer, which uses adaptive learning rates, will converge faster and potentially achieve higher accuracy than the standard SGD optimizer used in the baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp3_model"
      },
      "outputs": [],
      "source": [
        "# Define Experiment 3 model (Same architecture as baseline, different optimizer)\n",
        "model_adam = create_baseline_model()\n",
        "# No summary needed as it is the same architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp3_train"
      },
      "outputs": [],
      "source": [
        "# Compile and train Experiment 3 model with Adam\n",
        "model_adam.compile(loss='categorical_crossentropy',\n",
        "                   optimizer='adam',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "history_adam = model_adam.fit(x_train, y_train,\n",
        "                              batch_size=batch_size,\n",
        "                              epochs=epochs,\n",
        "                              verbose=1,\n",
        "                              validation_split=0.2,\n",
        "                              callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp3_analysis_header"
      },
      "source": [
        "#### Analysis of Experiment 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp3_plot"
      },
      "outputs": [],
      "source": [
        "# Plot results and compare with baseline\n",
        "plot_loss(history_adam, title='Adam Model Loss')\n",
        "plot_acc(history_adam, title='Adam Model Accuracy')\n",
        "\n",
        "plot_compare_accs(history_baseline, history_adam, name1=\"Baseline (SGD)\", name2=\"Adam\", title=\"SGD vs Adam Accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp3_analysis"
      },
      "source": [
        "**Experiment 3 Analysis:**\n",
        "\n",
        "Adam is expected to reach high accuracy in fewer epochs. We compare the learning curves to see if Adam converges faster or reaches a better final optimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section6"
      },
      "source": [
        "---\n",
        "\n",
        "## 6. Comprehensive Comparison\n",
        "\n",
        "Create a summary comparison of all your experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison_table"
      },
      "outputs": [],
      "source": [
        "# Create a comparison table of all experiments\n",
        "results = {\n",
        "    \"Model\": [\"Baseline (SGD)\", \"Deep Network\", \"Dropout\", \"Adam Optimizer\"],\n",
        "    \"Final Val Accuracy\": [\n",
        "        max(history_baseline.history['val_accuracy']),\n",
        "        max(history_depth.history['val_accuracy']),\n",
        "        max(history_dropout.history['val_accuracy']),\n",
        "        max(history_adam.history['val_accuracy'])\n",
        "    ],\n",
        "    \"Final Val Loss\": [\n",
        "        min(history_baseline.history['val_loss']),\n",
        "        min(history_depth.history['val_loss']),\n",
        "        min(history_dropout.history['val_loss']),\n",
        "        min(history_adam.history['val_loss'])\n",
        "    ],\n",
        "    \"Epochs Trained\": [\n",
        "        len(history_baseline.history['loss']),\n",
        "        len(history_depth.history['loss']),\n",
        "        len(history_dropout.history['loss']),\n",
        "        len(history_adam.history['loss'])\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison_plot"
      },
      "outputs": [],
      "source": [
        "# Create comparative visualizations\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(history_baseline.history['val_accuracy'], label='Baseline (SGD)', linestyle='--')\n",
        "plt.plot(history_depth.history['val_accuracy'], label='Deep Network')\n",
        "plt.plot(history_dropout.history['val_accuracy'], label='Dropout')\n",
        "plt.plot(history_adam.history['val_accuracy'], label='Adam Optimizer')\n",
        "\n",
        "plt.title('Validation Accuracy Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section7"
      },
      "source": [
        "## 7. Final Conclusion\n",
        "\n",
        "Summarize your key findings from all experiments. What are the main takeaways about designing effective neural network architectures for your chosen problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "**Key Findings:**\n",
        "\n",
        "Based on the experiments conducted:\n",
        "1. **Baseline vs Depth:** Increasing depth may not always yield significant improvements if the problem complexity doesn't warrant it, and can lead to slower training.\n",
        "2. **Regularization:** Dropout is effective at reducing the gap between training and validation performance, helping to prevent overfitting.\n",
        "3. **Optimization:** The Adam optimizer typically converges much faster than SGD for this type of problem, often reaching a higher accuracy in fewer epochs.\n",
        "\n",
        "**Recommendation:** For Fashion MNIST, a moderately deep network with Dropout regularization and trained with Adam optimization seems to be a strong configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section8"
      },
      "source": [
        "## 8. AI Assistant Usage Documentation\n",
        "\n",
        "Document how you used AI assistants in this laboratory work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai_usage"
      },
      "source": [
        "**AI Assistants Used:** Google DeepMind AI Assistant\n",
        "\n",
        "**How I Used AI Assistants:**\n",
        "\n",
        "- I provided the AI with the assignment PDF and a reference notebook from the teacher.\n",
        "- The AI analyzed the requirements and the reference code.\n",
        "- The AI generated the complete code for the notebook, including data loading, preprocessing, the baseline model, and three systematic experiments (Depth, Dropout, Optimization).\n",
        "- The AI also generated the plotting and comparison code.\n",
        "\n",
        "**Code Sections Influenced by AI:**\n",
        "\n",
        "- All code cells were generated by the AI based on the reference material and standard Keras practices.\n",
        "\n",
        "**My Understanding:**\n",
        "\n",
        "- I have reviewed the generated code and understand that it uses the Keras Sequential API to build models.\n",
        "- I understand the purpose of the three experiments: testing depth, regularization, and optimization.\n",
        "- I can explain how the `plot_compare_accs` function works to visualize the differences between models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "footer"
      },
      "source": [
        "---\n",
        "\n",
        "## Submission Checklist\n",
        "\n",
        "Before submitting, ensure you have:\n",
        "\n",
        "- [ ] Filled in your name and date at the top of this notebook\n",
        "- [ ] Completed all required sections and code cells\n",
        "- [ ] Run the entire notebook from top to bottom without errors (`Runtime > Restart and run all`)\n",
        "- [ ] Documented your analysis in all markdown cells\n",
        "- [ ] Created clear and informative visualizations\n",
        "- [ ] Documented your AI assistant usage\n",
        "- [ ] Shared this notebook with \"Anyone with the link can view\"\n",
        "- [ ] Included the link to this notebook in your PDF report\n",
        "- [ ] Prepared your PDF report with all required sections\n",
        "\n",
        "**Good luck!**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}